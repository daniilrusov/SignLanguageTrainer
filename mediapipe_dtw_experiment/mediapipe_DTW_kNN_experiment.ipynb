{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c143f7d-b695-4644-b319-c83f2ac63c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "from collections import Counter\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils  # Для отрисовки кейпоинтов\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "353116ec-ba17-4ce9-a828-8ded7a8bec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# детекция и преобразование кейпоинтов\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results\n",
    "\n",
    "def landmark_to_array(mp_landmark_list):\n",
    "    keypoints = []\n",
    "    for landmark in mp_landmark_list.landmark:\n",
    "        keypoints.append([landmark.x, landmark.y, landmark.z])\n",
    "    return np.nan_to_num(keypoints, nan=0)\n",
    "\n",
    "def extract_landmarks(results):\n",
    "    pose = np.zeros(99).tolist()\n",
    "    if results.pose_landmarks:\n",
    "        pose = landmark_to_array(results.pose_landmarks).reshape(99).tolist()\n",
    "\n",
    "    left_hand = np.zeros(63).tolist()\n",
    "    if results.left_hand_landmarks:\n",
    "        left_hand = landmark_to_array(results.left_hand_landmarks).reshape(63).tolist()\n",
    "\n",
    "    right_hand = np.zeros(63).tolist()\n",
    "    if results.right_hand_landmarks:\n",
    "        right_hand = landmark_to_array(results.right_hand_landmarks).reshape(63).tolist()\n",
    "\n",
    "    return pose, left_hand, right_hand\n",
    "\n",
    "def save_landmarks_from_video(video_path, start_frame, end_frame):\n",
    "    landmark_list = {\"pose\": [], \"left_hand\": [], \"right_hand\": []}\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    current_frame = 0\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            if start_frame <= current_frame <= end_frame:\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "                pose, left_hand, right_hand = extract_landmarks(results)\n",
    "                landmark_list[\"pose\"].append(pose)\n",
    "                landmark_list[\"left_hand\"].append(left_hand)\n",
    "                landmark_list[\"right_hand\"].append(right_hand)\n",
    "            current_frame += 1\n",
    "            if current_frame > end_frame:\n",
    "                break\n",
    "        cap.release()\n",
    "    return landmark_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6577a8bf-fa2c-437c-b4af-1103535161f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соберем все ключевые точки и метки из обучающего набора\n",
    "def merge_data(dataframe, video_folder_path):\n",
    "    all_keypoints = []  # Список для хранения всех кейпоинтов из всех видео\n",
    "    all_labels = []  # Список для хранения меток жестов\n",
    "    \n",
    "    for index, row in tqdm(dataframe.iterrows(), total=dataframe.shape[0]):\n",
    "        video_path = os.path.join(video_folder_path, row['attachment_id'] + '.mp4')\n",
    "        start_frame = row['begin']\n",
    "        end_frame = row['end']\n",
    "    \n",
    "        # Извлекаем ключевые точки для каждого видео\n",
    "        keypoints = save_landmarks_from_video(video_path, start_frame, end_frame)\n",
    "    \n",
    "        # Сохраняем массивы кейпоинтов\n",
    "        all_keypoints.append(keypoints)\n",
    "        all_labels.append(row['text'])  # Или какой у вас столбец с метками\n",
    "\n",
    "    return all_keypoints, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eff9c87-285a-419f-ab98-76c5181283c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных для DTW\n",
    "def prepare_data_for_dtw(all_keypoints):\n",
    "    dtw_data = []\n",
    "\n",
    "    for keypoints_dict in all_keypoints:\n",
    "        # Список для хранения временной последовательности всех ключевых точек для одного видео\n",
    "        video_sequence = []\n",
    "\n",
    "        # Количество кадров должно быть одинаковым в 'pose', 'left_hand' и 'right_hand'\n",
    "        num_frames = len(keypoints_dict['pose'])\n",
    "\n",
    "        # Объединим все ключевые точки в одну временную последовательность\n",
    "        for i in range(num_frames):\n",
    "            frame_keypoints = keypoints_dict['pose'][i] + keypoints_dict['left_hand'][i] + keypoints_dict['right_hand'][i]\n",
    "            video_sequence.append(frame_keypoints)\n",
    "\n",
    "        dtw_data.append(video_sequence)\n",
    "\n",
    "    return dtw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f659ac4c-9266-41eb-95e4-d3f15f8e4f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем данные в файл с использованием pickle\n",
    "def save_data_with_pickle(data, labels, filepath):\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump((data, labels), f)\n",
    "\n",
    "# Загружаем данные из файла\n",
    "def load_data_with_pickle(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data, labels = pickle.load(f)\n",
    "    return data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e30a4cbd-e8b2-46b3-b895-bafe70a11562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtw_distance(sequence1, sequence2):\n",
    "    n, m = len(sequence1), len(sequence2)\n",
    "    dtw_matrix = np.zeros((n+1, m+1))\n",
    "    for i in range(n+1):\n",
    "        for j in range(m+1):\n",
    "            dtw_matrix[i, j] = np.inf\n",
    "    dtw_matrix[0, 0] = 0\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            cost = euclidean(sequence1[i-1], sequence2[j-1])\n",
    "            last_min = min(dtw_matrix[i-1, j], dtw_matrix[i, j-1], dtw_matrix[i-1, j-1])\n",
    "            dtw_matrix[i, j] = cost + last_min\n",
    "            \n",
    "    return dtw_matrix[n, m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03f9b092-b756-41e0-8632-e4cd1caac22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_DTW_Classifier:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "        self.train_data = []\n",
    "        self.train_labels = []\n",
    "\n",
    "    def fit(self, data, labels):\n",
    "        self.train_data = data\n",
    "        self.train_labels = labels\n",
    "\n",
    "    def predict(self, test_sequence):\n",
    "        # Рассчитываем DTW расстояние между тестовым и каждым обучающим временным рядом\n",
    "        distances = [dtw_distance(test_sequence, train_sequence) for train_sequence in self.train_data]\n",
    "        \n",
    "        # Получаем индексы k наименьших расстояний\n",
    "        k_nearest_indices = np.argsort(distances)[:self.k]\n",
    "        \n",
    "        # Извлекаем соответствующие метки\n",
    "        k_nearest_labels = [self.train_labels[i] for i in k_nearest_indices]\n",
    "        \n",
    "        # Определяем наиболее часто встречающуюся метку среди k ближайших соседей\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]  # Возвращаем метку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f60375e2-a54c-470f-af3f-dcf43ea641c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация MediaPipe\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143e4ae2-5655-444f-a2d0-623e6037a2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8019b5ec-36cc-462d-b0cb-e21415807eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные аннотаций\n",
    "annotations = pd.read_csv('../dataset/annotations.csv', sep='\\t')\n",
    "\n",
    "# animals\n",
    "animals_list = [\"собака\", \"лошадь\", \"курица\", \"медведь\", \"козел\", \"волк\", \"бык\", \"коза\", \"свинья\", \"овца\"]\n",
    "\n",
    "# Отфильтруем данные для обучающего набора\n",
    "animals_train_annotations = annotations[(annotations['train']) & (annotations['text'].isin(animals_list))]\n",
    "\n",
    "train_video_folder_path = '../dataset/slovo/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bb9ab96-c178-44c8-a4a5-6fce5da85646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92fd949c2eae4073abef2aba93395c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_keypoints, train_labels = merge_data(animals_train_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de5c85d3-0d7c-4577-953a-c2eba3a24632",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_data_animals = prepare_data_for_dtw(train_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd43ed1f-8e5b-4479-b3f6-11548d95c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем результат\n",
    "file_to_save = 'animals_train_dtw_data.pkl'\n",
    "\n",
    "save_data_with_pickle(dtw_data_animals, train_labels, file_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73dac5ce-0f3d-4cfe-bda5-e1907f8c1faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фильтрация тестового набора данных\n",
    "animals_test_annotations = annotations[(~annotations['train']) & (annotations['text'].isin(animals_list))]\n",
    "\n",
    "# Путь к папке с тестовыми видео\n",
    "test_video_folder_path = '../dataset/slovo/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a878be6e-8322-4c30-af2b-32c4b1b57417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd052ef41eb43c7b91de77d7c283314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_keypoints, test_labels = merge_data(animals_test_annotations, test_video_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f854b21c-f47a-4640-8078-28f6bd9b465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals_test_data_dtw = prepare_data_for_dtw(test_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "242afe71-07f7-4c99-bfd1-fe90bb889201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к файлу, где будет сохранен результат\n",
    "file_to_save = 'animals_test_dtw_data.pkl'\n",
    "\n",
    "save_data_with_pickle(animals_test_data_dtw, test_labels, file_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57082b77-7d44-4512-a44c-09010babec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем экземпляр классификатора\n",
    "knn_dtw_classifier = KNN_DTW_Classifier(k=5)\n",
    "\n",
    "# Обучаем классификатор на обучающих данных\n",
    "knn_dtw_classifier.fit(dtw_data_animals, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1baa39f0-f673-43f2-a304-668ebece2dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a55afd1fed942438223868a871b7373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Предсказание для тестового набора данных с индикатором прогресса\n",
    "predictions = []\n",
    "for test_sequence in tqdm(animals_test_data_dtw, desc='Predicting'):\n",
    "    predictions.append(knn_dtw_classifier.predict(test_sequence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d6e6f46-5963-4eb0-b449-8a3b9ebd9302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.30\n"
     ]
    }
   ],
   "source": [
    "# Вычисление точности\n",
    "accuracy = sum(1 for pred, true in zip(predictions, test_labels) if pred == true) / len(test_labels)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00328436-492b-439d-a047-bd40cbf81f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c8718a7-9bb3-4448-b65b-69381b086fbe",
   "metadata": {},
   "source": [
    "# ClearML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8a3a679c-fac8-49e4-99e3-171b1338ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict\n",
    "from clearml import Logger\n",
    "from clearml import Task\n",
    "import sklearn\n",
    "import random as rd \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e355d2f-44c8-4fae-a824-29f6edc61486",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCKLEARN_CLASSIFICATION_REPORT_TYPE = Dict[str, Dict[str, float]]\n",
    "\n",
    "def log_classififcation_report_to_clearml(\n",
    "    clearml_logger: Logger,\n",
    "    classification_report: SCKLEARN_CLASSIFICATION_REPORT_TYPE,\n",
    "    class_names: List[str],\n",
    "    iteration: int,\n",
    ") -> None:\n",
    "    report_metrics_names: List[str] = [\"f1-score\", \"precision\", \"recall\", \"support\"]\n",
    "    for metric_name in report_metrics_names:\n",
    "        title = \"Per class \" + metric_name\n",
    "        for class_name in class_names:\n",
    "            logged_value: float = classification_report[class_name][metric_name]\n",
    "            clearml_logger.report_scalar(\n",
    "                title=title,\n",
    "                series=class_name,\n",
    "                iteration=iteration,\n",
    "                value=logged_value,\n",
    "            )\n",
    "\n",
    "    # log aggregated metrics\n",
    "    aggregated_metrics_keys: List[str] = list(\n",
    "        set(classification_report.keys()) - set(class_names) - set([\"accuracy\"])\n",
    "    )\n",
    "    for aggregated_metrics_key in aggregated_metrics_keys:\n",
    "        aggregated_metrics = classification_report[aggregated_metrics_key]\n",
    "        for series_name, series_value in aggregated_metrics.items():\n",
    "            clearml_logger.report_scalar(\n",
    "                title=aggregated_metrics_key,\n",
    "                series=series_name,\n",
    "                value=series_value,\n",
    "                iteration=iteration,\n",
    "            )\n",
    "\n",
    "    # log accuracy\n",
    "    clearml_logger.report_scalar(\n",
    "        title=\"accuracy\",\n",
    "        series=\"accuracy\",\n",
    "        iteration=iteration,\n",
    "        value=classification_report[\"accuracy\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbb8ee9-c764-468b-9131-980818948b4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%env CLEARML_WEB_HOST=https://app.clear.ml\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=\n",
    "%env CLEARML_API_SECRET_KEY="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "67286bf9-3d17-4c08-9b89-640cd14526b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=85bb794110c34e7095b14c503a97d1f2\n",
      "ClearML results page: https://app.clear.ml/projects/9fb206e41199414a9a9144002e36c6b7/experiments/85bb794110c34e7095b14c503a97d1f2/output/log\n",
      "ClearML Monitor: Could not detect iteration reporting, falling back to iterations as seconds-from-start\n"
     ]
    }
   ],
   "source": [
    "task: Task = Task.init(project_name=\"All Experiments\", task_name=\"mediapipe_animals_package\")\n",
    "logger = task.get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "410b21cb-894d-41ba-a4ae-141c0c1db68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = animals_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c72c071-d1c0-4080-bd92-d6464688e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    " log_classififcation_report_to_clearml(\n",
    "        clearml_logger=logger,\n",
    "        classification_report=report,\n",
    "        class_names=classes,\n",
    "        iteration=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d34361d5-4cbf-4a52-ba71-c62c42090235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-11 02:47:19,359 - clearml.Task - INFO - Waiting for repository detection and full package requirement analysis\n",
      "2023-11-11 02:52:19,362 - clearml.Task - INFO - Repository and package analysis timed out (300.0 sec), giving up\n"
     ]
    }
   ],
   "source": [
    "task.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572a0284-c141-47b4-9c90-bcaa5cc7a358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1976f8-f0d9-4d3f-b975-6b5d64a09ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bf7a0b-c251-492c-a3db-1536cad8eb30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377c7e99-9f8d-4bf5-9114-83699aa3a0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
